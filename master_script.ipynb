{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specifications (Modifiable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title = \"cudatest\" \n",
    "\n",
    "execution_profiles = ['default','sparse','CNN','local_patch','CNN_pool']\n",
    "execution_profile = execution_profiles[0]\n",
    "\n",
    "train_model = True # if this was set to false, the script would only plot and save figures based on your local model\n",
    "\n",
    "mult_lr = True # this defines whether you want to train the model multiple times with different learning rate. If switched off, the model will use 0.0001 which is an optimum value by experimentation.\n",
    "\n",
    "current_spread = 1 # this defines the Electric Receptive Field (ERF) spread\n",
    "\n",
    "elec_side_dim = 8 # this defines a elec_side_dim*elec_side_dim 2D electrodes array, overlayed on top of the image\n",
    "\n",
    "neu_side_dim = 16 # this defines a neu_side_dim*neu_side_dim 2D neuron array, overlayed on top of the image\n",
    "\n",
    "noise = 0.05 # this defines the noise \n",
    "num_ftrmap = 0\n",
    "if execution_profile == 'CNN_pool':\n",
    "    num_ftrmap = 20\n",
    "\n",
    "    kernal_size = 16\n",
    "    \n",
    "if execution_profile == 'sparse':\n",
    "    _lambda = 0.000005 # this defines the penalty for \n",
    "\n",
    "if execution_profile == 'local_patch':\n",
    "    kernal_size = 8\n",
    "\n",
    "# options for activation functions are \"linear\", \"2sig\" and \"ReLU\"\n",
    "activ_funcs_options = [\"linear\", \"2sig\",\"ReLU\",\"sig\"]\n",
    "activ_func1 = activ_funcs_options[0] # This will be the activation function for layer1 (encoding layer)\n",
    "activ_func2 = activ_funcs_options[3] # This will be the activation function for layer2 (LNL layer)\n",
    "activ_func3 = activ_funcs_options[2] # This will be the activation function for layer2 (LNL layer)\n",
    "af_array = [activ_func1,activ_func2,activ_func3]\n",
    "# shift and magnitude defines the 2sig function shape\n",
    "if activ_func1 == '2sig' or activ_func2 == '2sig':\n",
    "    # go to this website to preview shape: https://www.desmos.com/calculator/ote7ccaecn\n",
    "    shift = 9  # this defines the distance of the 2 sigmoid function from origin \n",
    "    magnitude = 0.5 # this defines the slope of the sigmoid function\n",
    "# shift and magnitude defines the 2sig function shape\n",
    "elif activ_func1 == 'sig' or activ_func2 == 'sig':\n",
    "    # go to this website to preview shape: https://www.desmos.com/calculator/lls9xi44z4\n",
    "    shift = 2   # this defines the distance of the sigmoid function from origin \n",
    "    magnitude = 2 # this defines the slope of the sigmoid function\n",
    "else:\n",
    "    shift = 0\n",
    "    magnitude = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Specifications (fixed under most circumstances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rate = 0.3 # this is an optimum value and should not change unless it is certain that this value is negatively impacting the model\n",
    "\n",
    "img_side_dim = 32 # image side dimension, assuming image is a square. If CIFAR is used, always set this to 32\n",
    "\n",
    "activ_spread= 0 # this is an obsolete parameter, always set to 0 \n",
    "\n",
    "n_epochs = 50 # this is an optimum value that works in most cases, only adjust if absolutely neccessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import functions from scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from LNL import define_save_LNL_model\n",
    "from Full_model import define_model,train_and_save\n",
    "from sparse_model_v2 import define_model_sparse,train_and_save_sparse\n",
    "from image_receptive_field import visualize_img_recep,visualize_img_recon_recep\n",
    "from compare_imgs import show_img_compare\n",
    "from Full_model_CNN import define_model_CNN,train_and_save_CNN\n",
    "from model_summary import show_generator,visualize_weights\n",
    "from plot_error import show_error,comp_error\n",
    "from Full_model_local_patch import define_model_local,train_and_save_local\n",
    "from Full_model_CNN_poolfromlayer import define_model_CNN_pool,train_and_save_CNN_pool\n",
    "from Pearson_correlation import Pearson_corr_comp\n",
    "from pseudoinverse_visualisation import visualise_psuedo\n",
    "\n",
    "device1 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define model paths for saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "LNL_model_path = cwd+'/data/LNL_model.pth'\n",
    "model_path = cwd+f'/data/model_{model_title}_lr = 0.0001.pth'\n",
    "data_path = cwd + f'/data/NN_{model_title}_output.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the LNL section of the model and saves it for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LNL layer with gaussian electrical receptive field\n",
    "W_d = define_save_LNL_model(LNL_model_path,elec_side_dim, neu_side_dim, activ_spread, current_spread,FHWM=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and save the model for result demo\n",
    "Default Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayacolyte/micromamba/envs/NN/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataLoaders ready\n",
      "Convesion to tensor on cpu completed\n",
      "Epoch [0/50], Loss: 0.3389\n",
      "Epoch [10/50], Loss: 0.3141\n"
     ]
    }
   ],
   "source": [
    "if execution_profile == 'default':\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = 'cpu'\n",
    "    AutoEncoder = define_model(device,elec_side_dim,neu_side_dim, LNL_model_path, drop_rate, af_array,shift,magnitude,noise)\n",
    "\n",
    "    if train_model:  \n",
    "        start_time = time.time()\n",
    "        train_and_save(device,n_epochs,AutoEncoder,model_title,mult_lr)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default FC model with CNN as 1st layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_profile == 'CNN':\n",
    "    AutoEncoder = define_model_CNN(elec_side_dim,neu_side_dim, LNL_model_path, drop_rate, af_array,shift,magnitude,noise,img_side_dim)\n",
    "    if train_model:  \n",
    "        start_time = time.time()\n",
    "        train_and_save_CNN(n_epochs,AutoEncoder,model_title,mult_lr)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN but pooling from feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_profile == 'CNN_pool':\n",
    "    \n",
    "    AutoEncoder = define_model_CNN_pool(elec_side_dim,neu_side_dim, LNL_model_path, drop_rate, af_array, shift,magnitude,noise,img_side_dim,num_ftrmap,kernal_size)\n",
    "    if train_model:  \n",
    "        start_time = time.time()\n",
    "        train_and_save_CNN_pool(n_epochs,AutoEncoder,model_title,mult_lr,device1)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "local patch custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_profile == 'local_patch':\n",
    "    # code below generates a mask that forces weights other than those around the electrode to zero, hence introducing electrode with localised ERF\n",
    "    input_size = img_side_dim**2\n",
    "    output_size = elec_side_dim**2\n",
    "    mask_np = np.zeros((input_size, output_size))\n",
    "    for i in range(elec_side_dim): \n",
    "        for j in range(elec_side_dim):\n",
    "            curr_elec = i*elec_side_dim + j  # zero based current electrode (first one is 0)\n",
    "            rows = range(max(0, (4*i - 2)), min(img_side_dim,(4*i + 6)))\n",
    "            for row in rows: \n",
    "                start = max(0,(4*j - 2))\n",
    "                end =  min((4*j-2+kernal_size),img_side_dim)\n",
    "                # Calculate indices\n",
    "                indices = [row * img_side_dim + col for col in range(start, end)]\n",
    "                mask_np[indices,curr_elec] = 1\n",
    "    mask_torch = torch.from_numpy(mask_np)\n",
    "    # define the model with this mask applied\n",
    "    AutoEncoder = define_model_local(elec_side_dim,neu_side_dim, LNL_model_path, drop_rate, af_array,shift,magnitude,noise,img_side_dim, mask_torch)\n",
    "    if train_model:  \n",
    "        start_time = time.time()\n",
    "        train_and_save_local(n_epochs,AutoEncoder,model_title,mult_lr)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_profile == 'sparse':\n",
    "    AutoEncoder = define_model_sparse(elec_side_dim,neu_side_dim, LNL_model_path, drop_rate, af_array,shift,magnitude,noise)\n",
    "    if train_model:  \n",
    "        start_time = time.time()\n",
    "        train_and_save_sparse(n_epochs,AutoEncoder,model_title,_lambda,mult_lr = False)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_error(data_path,model_title)\n",
    "comp_error(data_path,model_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from LNL import W_d\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "cwd = os.getcwd()\n",
    "model_title1 = 'fc_25%_noise_5%wnoise_30dropout_30epoch'\n",
    "model_title2 = 'CNNpool_3dropout_15%n_5%w'\n",
    "data_path1 = cwd + f'/data/NN_{model_title1}_output.pkl'\n",
    "data_path2 = cwd + f'/data/NN_{model_title2}_output.pkl'\n",
    "\n",
    "with open(data_path1, 'rb') as file1, open(data_path2, 'rb') as file2:\n",
    "    data1 = pickle.load(file1)\n",
    "    data2 = pickle.load(file2)\n",
    "    #print(data2[0])\n",
    "    N_epoch = 30\n",
    "    x = np.arange(N_epoch + 1)\n",
    "    #print(data[0])\n",
    "    log_data1 = data1\n",
    "    log_data2 = data2\n",
    "    for i in range(data1[0].shape[1]) :\n",
    "        for j in range(data1[0].shape[0]):\n",
    "\n",
    "            log_data1[0][j,i] = math.log(data1[0][j,i])\n",
    "            log_data2[0][j,i] = math.log(data2[0][j,i])\n",
    "            #print(i)\n",
    "\n",
    "    for i in range(data1[1].shape[1]) :\n",
    "        for j in range(data1[1].shape[0]):\n",
    "\n",
    "            log_data1[1][j,i] = math.log(data1[1][j,i])\n",
    "            log_data2[1][j,i] = math.log(data2[1][j,i])\n",
    "            #print(i)\n",
    "    print(data1[0].shape, data2[0].shape)\n",
    "    print(data1[1].shape, data2[1].shape)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x,log_data1[0][:], label='FC Training Error FC', color=(0.83, 0.14, 0.14))  # Skip the first entry if it contains the mean\n",
    "    plt.plot(x,log_data1[1][:], label='FC Validation Error', color=(1.00, 0.54, 0.00))  # Skip the first entry if it contains the mean\n",
    "    plt.plot(x,log_data2[0][:], label='CNN Training Error', color=(0.47, 0.25, 0.80))  # Skip the first entry if it contains the mean\n",
    "    plt.plot(x,np.squeeze(log_data2[1][:],0), label='CNN Validation Error', color=(0.25, 0.80, 0.54))  # Skip the first entry if it contains the mean\n",
    "        \n",
    "    plt.title('Training and Validation Error over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log Scale Error')\n",
    "    plt.legend()\n",
    "    plt.savefig('Error Comparison between CNN and FC.png', format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch\n",
    "output_test_flat, layer1_flat, layer2_flat,neu_maps = show_img_compare(model_path, AutoEncoder,model_title,execution_profile)\n",
    "\n",
    "Pearson_corr_comp(neu_maps,model_title)\n",
    "visualise_psuedo(model_path, AutoEncoder,model_title,execution_profile)\n",
    "# layer1_flat = layer1_flat.detach().numpy()\n",
    "# test_lyr2_flat = layer1_flat @ (W_d.transpose())\n",
    "\n",
    "\n",
    "# sigmoid1 = 1/(1+np.exp(magnitude * (test_lyr2_flat + shift)))\n",
    "# sigmoid2 = 1/(1+np.exp(-1*magnitude * (test_lyr2_flat - shift)))\n",
    "# test_lyr2_flat = sigmoid1 + sigmoid2\n",
    "\n",
    "# test_lyr2_flat = torch.tensor(test_lyr2_flat)\n",
    "\n",
    "\n",
    "\n",
    "# side_dim = int(math.sqrt(test_lyr2_flat.shape[1]))\n",
    "# test_lyr2 = test_lyr2_flat.view(test_lyr2_flat.shape[0],side_dim,side_dim)\n",
    "# test_lyr2_np = test_lyr2.detach().numpy()\n",
    "\n",
    "# lyr2 = layer2_flat.view(layer2_flat.shape[0],side_dim,side_dim)\n",
    "# lyr2_np = lyr2.detach().numpy()\n",
    "\n",
    "# # Create a figure with 2 subplots side by side\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# # Plotting on the first subplot\n",
    "# img1 = ax1.imshow(test_lyr2_np[4],cmap='gray')\n",
    "\n",
    "# # Plotting on the second subplot\n",
    "# img2 = ax2.imshow(lyr2_np[4],cmap='gray')\n",
    "# fig.colorbar(img1, ax=ax1, fraction=0.046, pad=0.04) \n",
    "# fig.colorbar(img2, ax=ax2, fraction=0.046, pad=0.04) \n",
    "# # Adjust the space between the plots\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Display the plots\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_FFT = True\n",
    "model_loaded = visualize_img_recep(model_path, AutoEncoder, img_side_dim,elec_side_dim,model_title,show_FFT,execution_profile)\n",
    "#plot(model_loaded.layer3.weight.data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_img_recon_recep(model_path, AutoEncoder, neu_side_dim, model_title,show_FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_profile != \"CNN\" and execution_profile != \"CNN_pool\":\n",
    "    visualize_weights(AutoEncoder,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_generator(model_path,AutoEncoder, af_array, magnitude, shift,model_title,execution_profile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
